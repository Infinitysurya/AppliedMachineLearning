{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d32bf-d2f3-4a98-a042-6d5398dcbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def load_splits(train_path=\"train.csv\", val_path=\"validation.csv\", test_path=\"test.csv\"):\n",
    "    \"\"\"Loads train, validation, and test splits from CSV files.\"\"\"\n",
    "    train = pd.read_csv(train_path)\n",
    "    val = pd.read_csv(val_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    return train, val, test\n",
    "\n",
    "def preprocess_text(train, val, test):\n",
    "    \"\"\"Converts text data to TF-IDF vectors.\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train = vectorizer.fit_transform(train['message'])\n",
    "    X_val = vectorizer.transform(val['message'])\n",
    "    X_test = vectorizer.transform(test['message'])\n",
    "\n",
    "    y_train = train['label']\n",
    "    y_val = val['label']\n",
    "    y_test = test['label']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, vectorizer\n",
    "\n",
    "def fit_model(model, X_train, y_train):\n",
    "    \"\"\"Fits a model on the training data.\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def score_model(model, X, y):\n",
    "    \"\"\"Scores the model on given data.\"\"\"\n",
    "    return model.score(X, y)\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"Evaluates the model using accuracy and classification report.\"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    report = classification_report(y, y_pred)\n",
    "    return acc, report\n",
    "\n",
    "def validate_model(model, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Fits on train, scores on train and validation, evaluates on train and validation.\"\"\"\n",
    "    model = fit_model(model, X_train, y_train)\n",
    "    \n",
    "    print(\"Train Score:\", score_model(model, X_train, y_train))\n",
    "    print(\"Validation Score:\", score_model(model, X_val, y_val))\n",
    "    \n",
    "    train_acc, train_report = evaluate_model(model, X_train, y_train)\n",
    "    val_acc, val_report = evaluate_model(model, X_val, y_val)\n",
    "    \n",
    "    print(\"\\nTrain Evaluation:\\n\", train_report)\n",
    "    print(\"\\nValidation Evaluation:\\n\", val_report)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def tune_hyperparameters(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Fine-tunes hyperparameters using train and validation data.\"\"\"\n",
    "    param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid, cv=3, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    print(\"Best Hyperparameters:\", grid.best_params_)\n",
    "    \n",
    "    return validate_model(best_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "def benchmark_models(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"Trains and evaluates three benchmark models, selecting the best one.\"\"\"\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Naive Bayes\": MultinomialNB(),\n",
    "        \"SVM\": SVC()\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model = validate_model(model, X_train, y_train, X_val, y_val)\n",
    "        test_acc, _ = evaluate_model(model, X_test, y_test)\n",
    "        \n",
    "        print(f\"Test Accuracy for {name}: {test_acc}\")\n",
    "        \n",
    "        if test_acc > best_score:\n",
    "            best_score = test_acc\n",
    "            best_model = model\n",
    "    \n",
    "    print(\"\\nBest Model:\", best_model)\n",
    "    return best_model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
